# ðŸš€ LLMLab

[![Version](https://img.shields.io/badge/version-0.1.0-blue)](https://github.com/ArivunidhiA/llmlab)
[![License](https://img.shields.io/badge/license-MIT-green)](LICENSE)
[![Status](https://img.shields.io/badge/status-production--ready-brightgreen)]()
[![Python](https://img.shields.io/badge/python-3.9+-blue)](https://www.python.org/)
[![Node](https://img.shields.io/badge/node-18+-blue)](https://nodejs.org/)

**Track and optimize your LLM API costs in seconds.** Know exactly what you're spending on Claude, GPT-4, and other LLMs â€” with zero code changes.

## ðŸ“‹ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Architecture](#-architecture)
- [Tech Stack](#-tech-stack)
- [Quick Start](#-quick-start)
- [Configuration](#ï¸-configuration)
- [API Documentation](#-api-documentation)
- [Deployment](#-deployment)
- [Performance](#-performance)
- [Development](#-development)
- [Testing](#-testing)
- [Troubleshooting](#-troubleshooting)
- [Contributing](#-contributing)
- [License](#-license)

---

## ðŸ’¡ Overview

LLMLab solves a critical problem: **developers have no visibility into LLM API costs.**

Most dev teams don't know how much they're spending on Claude or GPT until the bill arrives. LLMLab fixes this by:

âœ… **Real-time tracking** â€” See costs as they happen  
âœ… **Zero code changes** â€” Just swap your API key  
âœ… **Smart recommendations** â€” "Save $200/mo by switching to GPT-3.5"  
âœ… **Multiple providers** â€” OpenAI, Anthropic, Google Gemini  
âœ… **Beautiful dashboard** â€” Costs in real-time  
âœ… **CLI + SDK** â€” Use however you want  

**Perfect for:** Startups, AI teams, anyone tired of LLM bill shock.

---

## ðŸŽ¯ Features

### ðŸ’° Cost Tracking
- Real-time API call logging
- Automatic cost calculation
- Multi-provider support (OpenAI, Anthropic, Google Gemini)
- Daily/monthly/lifetime stats
- **Usage Logs Explorer** â€” Paginated, filterable, sortable view of every API call
- **Data Export** â€” Download logs as CSV or JSON with filters

### ðŸ“Š Dashboard
- Live cost breakdown by model
- Spending trends (30-day)
- Budget alerts & tracking
- **Cost Forecasting** â€” Linear trend projection for next month's spend
- **Anomaly Detection** â€” Z-score based alerts for spend spikes and token surges
- Beautiful UI (Apple-inspired)

### ðŸ·ï¸ Project Tags
- User-defined tags for cost attribution (e.g., "backend", "prod", "feature-x")
- Auto-tagging via `X-LLMLab-Tags` header
- Filter stats, logs, and exports by tag

### ðŸ”§ Developer Tools
- **CLI**: `llmlab status`, `llmlab optimize`, `llmlab proxy-key`, `llmlab export`
- **SDK**: `patch()` for zero-code integration, `set_tags()` for cost attribution, `@track_cost` decorator
- **API**: REST endpoints for everything
- **No code changes required** â€” Just swap env var

### ðŸŽ¨ Optimization
- Cost-saving recommendations
- Model comparison tool
- Budget enforcement
- Anomaly detection with webhook notifications

### ðŸš€ Production Ready
- **Streaming support** â€” Full SSE streaming proxy with post-stream cost logging
- **Docker deployment** â€” Multi-stage Dockerfile and docker-compose
- **CI/CD** â€” GitHub Actions for lint, test, build, deploy
- **Redis caching** â€” Semantic response cache with configurable TTL
- **Rate limiting** â€” Configurable per-endpoint rate limits
- **SQL-optimized queries** â€” Aggregation pushed to database for fast stats

---

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    YOUR APPLICATION                     â”‚
â”‚              (uses LLM API as normal)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ API Call
                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   LLMLab API Proxy/SDK     â”‚
        â”‚  (logs call + cost)        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ Forward to real API + Log
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  LLM Provider API             â”‚
        â”‚ (OpenAI/Anthropic/Google)    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ Response + Tokens
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Cost Database (Supabase)    â”‚
        â”‚  (stores cost records)        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Dashboard (Vercel)          â”‚
        â”‚   CLI Tool (PyPI)             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Backend** | FastAPI + Python | API server, cost calculations |
| **Frontend** | Next.js + React | Dashboard UI |
| **CLI** | Python Click | Command-line tool |
| **Database** | PostgreSQL (Supabase) | Cost data storage |
| **Deployment** | Railway + Vercel | Backend + frontend hosting |

---

## ðŸ› ï¸ Tech Stack

### Backend
```
FastAPI 0.104+        â†’ REST API framework
Python 3.9+           â†’ Language runtime
SQLAlchemy 2.0+       â†’ ORM
PostgreSQL 14+        â†’ Database
Pydantic 2.5+         â†’ Validation
```

### Frontend
```
Next.js 14+           â†’ Framework
React 18+             â†’ UI library
TypeScript 5+         â†’ Type safety
Tailwind CSS 3+       â†’ Styling
```

### Infrastructure
```
Railway               â†’ Backend hosting
Vercel                â†’ Frontend hosting
Supabase              â†’ Managed PostgreSQL
GitHub Actions        â†’ CI/CD
```

---

## ðŸš€ Quick Start

### Prerequisites

- Python 3.9+ (backend & CLI)
- Node 18+ (frontend)
- Git
- Docker (optional)

### Installation

```bash
# Clone repo
git clone https://github.com/ArivunidhiA/llmlab.git
cd llmlab

# Backend setup
cd backend
pip install -r requirements.txt
cp .env.example .env
# Edit .env with your DATABASE_URL

# Frontend setup
cd ../frontend
npm install
cp .env.example .env.local
# Edit .env.local with API_URL

# CLI setup
cd ../cli
pip install -e .

# Run all three
# Terminal 1: Backend
cd backend && uvicorn main:app --reload

# Terminal 2: Frontend
cd frontend && npm run dev

# Terminal 3: CLI test
llmlab --version
```

### First Steps

```bash
# 1. Initialize CLI
llmlab login

# 2. Configure your API keys
llmlab configure

# 3. View costs
llmlab stats

# 4. Get proxy key
llmlab proxy-key

# 5. Set monthly budget
llmlab budget 1000
```

---

## âš™ï¸ Configuration

### Environment Variables

**Backend** (`backend/.env`):
```env
DATABASE_URL=postgresql://user:password@host/dbname
JWT_SECRET=your-secret-key-here
ENCRYPTION_KEY=fernet-key-here
GITHUB_CLIENT_ID=your-github-id
GITHUB_CLIENT_SECRET=your-github-secret
CORS_ORIGINS=http://localhost:3000,https://yourdomain.com
```

**Frontend** (`frontend/.env.local`):
```env
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_GITHUB_CLIENT_ID=your-github-id
```

**CLI** (`~/.llmlab/config.json` â€” created automatically):
```json
{
  "jwt_token": "your-token",
  "api_keys": {
    "openai": "encrypted-key",
    "anthropic": "encrypted-key"
  },
  "user_id": "user-uuid"
}
```

---

## ðŸ“¡ API Documentation

### Authentication

All requests require JWT token in header:
```
Authorization: Bearer {token}
```

### Key Endpoints

#### Track API Call
```bash
POST /api/events/track
Content-Type: application/json

{
  "model": "gpt-4",
  "provider": "openai",
  "tokens_input": 500,
  "tokens_output": 200,
  "timestamp": "2024-02-09T10:00:00Z"
}

Response:
{
  "success": true,
  "data": {
    "cost_usd": 0.0175,
    "event_id": "evt_123"
  }
}
```

#### Get Cost Summary
```bash
GET /api/costs/summary?period=month

Response:
{
  "success": true,
  "data": {
    "total_usd": 1234.56,
    "by_model": [
      {"model": "gpt-4", "cost": 500, "calls": 100},
      {"model": "claude-3-opus", "cost": 400, "calls": 80}
    ],
    "daily_costs": [...]
  }
}
```

See full API docs in `/docs/API_SPEC.md`

---

## ðŸŒ Deployment

LLMLab uses **Railway** for the backend and **Vercel** for the frontend, with automated CI/CD via GitHub Actions.

### Prerequisites

1. A [Railway](https://railway.app/) account with a project
2. A [Vercel](https://vercel.com/) account linked to your GitHub repo
3. A [GitHub OAuth App](https://github.com/settings/developers) for authentication

### GitHub Repository Secrets

Set these in your repo: **Settings > Secrets and variables > Actions**:

| Secret | Description |
|--------|-------------|
| `RAILWAY_TOKEN` | Railway project deploy token |
| `VERCEL_TOKEN` | Vercel personal access token |

### Railway (Backend)

1. Create a new Railway project and add **PostgreSQL** and **Redis** add-ons.
2. Connect your GitHub repo to Railway (set root directory to `backend/`).
3. Set the following environment variables in the Railway dashboard:

| Variable | Value |
|----------|-------|
| `DATABASE_URL` | Auto-set by Railway PostgreSQL add-on |
| `REDIS_URL` | Auto-set by Railway Redis add-on |
| `JWT_SECRET` | Generate: `openssl rand -hex 32` |
| `ENCRYPTION_KEY` | Generate: `python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"` |
| `GITHUB_CLIENT_ID` | From your GitHub OAuth App |
| `GITHUB_CLIENT_SECRET` | From your GitHub OAuth App |
| `GITHUB_REDIRECT_URI` | `https://<your-railway-domain>/auth/github/callback` |
| `CORS_ORIGINS` | `https://<your-vercel-domain>.vercel.app` |
| `ENVIRONMENT` | `production` |

### Vercel (Frontend)

1. Import the repo on Vercel (set root directory to `frontend/`).
2. Set these environment variables:

| Variable | Value |
|----------|-------|
| `NEXT_PUBLIC_API_URL` | `https://<your-railway-domain>` |
| `NEXT_PUBLIC_GITHUB_CLIENT_ID` | From your GitHub OAuth App |
| `NEXT_PUBLIC_GITHUB_REDIRECT_URI` | `https://<your-vercel-domain>.vercel.app/auth/callback` |

### Docker (Self-hosted)

```bash
# 1. Copy .env.example and set your secrets
cp backend/.env.example .env
# Edit .env â€” at minimum set JWT_SECRET and ENCRYPTION_KEY

# 2. Start everything
docker compose up --build -d

# 3. Open dashboard
open http://localhost:3000
```

---

## ðŸ“ˆ Performance

### Benchmarks

| Metric | Target | Actual |
|--------|--------|--------|
| API response time | <100ms | ~45ms |
| Dashboard load | <2s | ~1.2s |
| CLI startup | <1s | ~350ms |
| Cost calculation | <10ms | ~3ms |

### Monitoring

- Sentry (error tracking)
- DataDog (performance)
- Railway logs (backend logs)
- Vercel analytics (frontend metrics)

---

## ðŸ’» Development

### Project Structure
```
llmlab/
â”œâ”€â”€ backend/           # FastAPI app
â”œâ”€â”€ frontend/          # Next.js app
â”œâ”€â”€ cli/               # Python CLI
â”œâ”€â”€ sdk/               # Python SDK
â”œâ”€â”€ docs/              # Documentation
â””â”€â”€ tests/             # Test files
```

### Local Development
```bash
# Install pre-commit hooks
pre-commit install

# Code formatting
black backend/ cli/
prettier --write frontend/

# Linting
flake8 backend/ cli/
eslint frontend/
```

---

## ðŸ§ª Testing

```bash
# Backend tests
cd backend && pytest --cov

# Frontend tests
cd frontend && npm test

# CLI tests
cd cli && pytest

# End-to-end
# Manually test: login â†’ configure â†’ stats
```

---

## ðŸ› Troubleshooting

| Issue | Solution |
|-------|----------|
| `ModuleNotFoundError` | Run `pip install -r requirements.txt` |
| `CORS error` | Check `CORS_ORIGINS` in `.env` |
| `Database connection failed` | Verify `DATABASE_URL` and Supabase is running |
| `401 Unauthorized` | Token expired or invalid. Run `llmlab login` |
| `CLI not found` | Run `pip install -e .` in cli/ folder |

---

## ðŸ¤ Contributing

1. Fork the repo
2. Create feature branch (`git checkout -b feature/your-feature`)
3. Commit changes (`git commit -m "feat: description"`)
4. Push branch (`git push origin feature/your-feature`)
5. Open Pull Request

See `/docs/guides/` for more details.

---

## ðŸ“„ License & Author

**License**: MIT (see LICENSE file)

**Author**: [@Ariv_2012](https://twitter.com/Ariv_2012)

**Built**: February 2026

---

## ðŸ“š Documentation

- Full documentation: `/docs/INDEX.md`
- API reference: `/docs/API_SPEC.md`
- Architecture: `/docs/ARCHITECTURE.md`
- Deployment guide: `/docs/guides/DEPLOYMENT.md`
- Social strategy: `/docs/social/`

---

**Ready to track your LLM costs?**

```bash
pip install llmlab-cli
llmlab login
llmlab status
```

**Enjoy. Build better. Save money.** ðŸš€
